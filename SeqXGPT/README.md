# Deep Learning Model -- SeqXGPT

Our model based on SeqXGPT, please refer to the [SeqXGPT](https://github.com/Jihuai-wpy/SeqXGPT/tree/main).

Our training checkpoints are saved on the [HuggingFace](https://huggingface.co/Roxanne-WANG/AI-Text-Detection).

## Datasets

Each dataset contains six files. Within each dataset folder, based on the source of AI-generated sentences in the document, they are organized into different files. You can refer to the requirements of different tasks in the paper to arrange and merge the files. Below are SeqXGPT-Bench and two important evaluation datasets. (This folder should be put under dataset/) The SeqXGPT-Bench is a sentence-level AI-generated text (AIGT) detection dataset used for the study of fine-grained AIGT detection.

We upload raw data and data with extracted features on the [HuggingFace](https://huggingface.co/datasets/Roxanne-WANG/AI-Text_Detection).

#### Raw Data Format

```python
{
    "text": "Media playback is unsupported on your device 21 June 2013 Last updated at 12:31 BST The Market Hall Cinema in Brynmawr used to be run by the local council but when it announced its funding would stop last month, work began to find a way to keep it going. Thanks to the efforts of a group of local volunteers, the cinema has been saved and reopened under a new community initiative. The group, called \"Brynmawr Foundation\", raised enough funds to take over the lease of the building and purchase new equipment. They plan to show a mix of classic and new films, as well as host events and live performances. The Market Hall Cinema has been an important part of the town's history since it first opened in 1894, and this new initiative ensures that it will continue to be a valuable resource for the community.", 
    "prompt_len": 254, 
    "label": "gpt3re"
}
```

​	**`text`**: The full document containing both human-written and AI-generated content.

​	**`prompt_len`**: An integer marks the boundary between the sentences generated by humans and those generated by AI. The first `prompt_len` characters of the input `text`, i.e., *text[:prompt\_len]*, are the sentences generated by humans, while the rest are generated by a particular language model.

​	**`label`**: The label for each sentence, and there are six types of labels in total: `gpt2`, `llama`, `gpt3re`, `human`.

#### Processed Data Format

```python
{
    "losses": [3.0821034908294678],
    "begin_idx_list": [1],
    "ll_tokens_list": [[0.0, 4.58919095993042, 4.58919095993042, ... , 3.2181057929992676]],
    "label_int": 3, 
    "label": "gpt3re",
    "text": "Media playback is unsupported on your device 21 June 2013 Last updated at 12:31 BST The Market Hall Cinema in Brynmawr used to be run by the local council but when it announced its funding would stop last month, work began to find a way to keep it going. Thanks to the efforts of a group of local volunteers, the cinema has been saved and reopened under a new community initiative. The group, called \"Brynmawr Foundation\", raised enough funds to take over the lease of the building and purchase new equipment. They plan to show a mix of classic and new films, as well as host events and live performances. The Market Hall Cinema has been an important part of the town's history since it first opened in 1894, and this new initiative ensures that it will continue to be a valuable resource for the community.", 
}
```

**`losses`**: A list of log-likelihood loss values indicating how well the model predicts the text.

**`begin_idx_list`**: A list marking the index where AI-generated content begins in the text.

**`ll_tokens_list`**: A list of lists containing log-likelihood scores for each token in the text.

**`label_int`**: An integer representing the categorical label of the text source.

**`label`**: A string indicating the origin of the text, such as `gpt2`, `llama`, `gpt3re`, `human`.

**`text`**: The full document containing both human-written and AI-generated content.


| label_int | label  | count |
|-----------|--------|-------|
| 0         | gpt2   | 6000  |
| 1         | llama  | 5904  |
| 2         | human  | 5997  |
| 3         | gpt3re | 5994  |

#### Document-Level Detection Dataset

A dataset used to evaluate the performance of various methods in document-level AIGT detection.

```python
{
    "text": "in this paper we consider the possible existence of unstable axisymmetric modes in kerr space times , resulting from exponentially growing solutions of the teukolsky equation .  we describe a transformation that casts the radial equation that results upon separation of variables in the teukolsky equation , in the form of a schrdinger equation , and combine the properties of the solutions of this equations with some recent results on the asymptotic behaviour of spin weighted spheroidal harmonics to prove the existence of an infinite family of unstable modes .  thus we prove that the stationary region beyond a kerr black hole inner horizon is unstable under gravitational linear perturbations .  we also prove that kerr space - time with angular momentum larger than its square mass , which has a naked singularity , is unstable .", 
    "label": "human"
}
```

​	**`text`** refers to an entire document.

​	**`label`** is the label for the document, and there are six types of labels in total: `gpt2`, `llama`, `gpt3re`, `human`.

#### OOD Sentence-Level Detection Dataset

A dataset used to evaluate the performance of various methods on OOD data.

**data format** is the same as the data format of [SeqXGPT-Bench](#seqxgpt-bench).


## Inference Server

We GPT2-xl (1.5B) to construct the original features of our SeqXGPT and the contrastive features for Sniffer.

You can launch the inference server through `backend_api.py`. The startup command is as follows:

```bash
# --model: [gpt2]
python backend_api.py --port 20098 --timeout 30000 --debug --model=gpt2 --gpu=0
```

## Feature Extraction

### Training Data

After successfully starting the related inference server, you can extract **the original features of SeqXGPT** using `gen_features.py`:

```bash
python dataset/gen_features.py --get_en_features --input_file dataset/SeqXGPT_raw/en_gpt2_lines.jsonl --output_file dataset/SeqXGPT_output/en_gpt2_lines.jsonl
```

### Testing Data

As for test dataset which does not contain `label`, use below argument to extract features:

```bash
python dataset/gen_features.py --get_unlabeled_features --input_file dataset/SeqXGPT_output/inference.jsonl --output_file dataset/SeqXGPT_output/inference_output.jsonl
```

## Models

### SeqXGPT

We have provided the **complete code** for the model, dataloader, and train/test-related function under the `SeqXGPT` folder.

Before training and testing, please refer to the [Feature Extraction](#feature-extraction) section to extract relevant features, which will serve as the `--data_path`. The reference command is as follows:

```bash
# split train / test dataset and then train. You can adjust the train/test ratio using '--train_ratio'.
python SeqXGPT/train.py --split_dataset --data_path dataset/SeqXGPT_output --train_path dataset/SeqXGPT_output/en_gpt2_tr.jsonl --test_path dataset/SeqXGPT_output/en_gpt2_te.jsonl --gpu=0
```

```bash
# train
python SeqXGPT/train.py --gpu=0
```

```bash
# test
python SeqXGPT/train.py --gpu=0 --do_test
```

```bash
# test document-level AIGT detection
python SeqXGPT/train.py --gpu=0 --do_test --test_content
```

In our modified version of SeqXGPT, we introduce three extra operations on the document-level wave (i.e., the sequence of log probabilities) to further refine feature extraction and enhance generalization:

#### I. Patch-based Averaging:
We divide the wave into small patches and compute the average within each patch. This operation acts as a smoothing mechanism that reduces local noise and variability. By aggregating local statistics, each patch more reliably represents the dominant trend in that segment of the wave, thereby making the subsequent feature extraction more robust.

#### II. 2D Convolution Processing:
Instead of relying solely on 1D convolution (or other sequential models), we apply 2D convolution on the wave. This approach allows the model to capture local patterns along two dimensions simultaneously—both across the temporal axis and across feature channels. The 2D convolution effectively extracts rich spatial correlations and inter-channel interactions, which enhances the model’s ability to discern subtle differences in the wave patterns.

#### III. Patch Shuffling:
After dividing the wave into patches, we shuffle the order of these patches. Shuffling serves as a data augmentation strategy that encourages the model to learn features that are invariant to the exact ordering of local segments. By reducing dependency on sequential order, the model becomes less prone to overfitting and gains improved generalization performance when faced with varied or perturbed input sequences.

## Experiment Results

We evaluated our model on two tasks:

- **Bi-classification:** The goal was to identify whether a text is human-written or AI-generated.
- **Multi-classification:** The task involved classifying texts into one of four categories: `human`, `GPT2`, `GPT3-re`, or `LLaMA`.

To better understand the contributions of our proposed modifications, we compared several variants of our model:

- **SeqXGPT:** The baseline model.
- **SeqXGPT (PA):** Incorporates patch-based averaging to smooth the log-probability wave, reducing local noise.
- **SeqXGPT (Conv):** Applies 2D convolution to extract local spatial correlations across the wave, enhancing feature robustness.
- **SeqXGPT (PS):** Uses patch shuffling as a data augmentation strategy, promoting invariance to the ordering of local segments.

### Bi-Classification

For the bi-classification task, the performance results (measured in accuracy) on the AI-generated text from GPT2, GPT3-re, and LLaMA are summarized in the table below:

|         | SeqXGPT | SeqXGPT (PA) | SeqXGPT (Conv) | SeqXGPT (ps) |
|---------|---------|--------------|----------------|--------------|
| **gpt2**    | 91.2%   | 92.3%        | 93.1%          | 92.8%        |
| **gpt3re**  | 90.5%   | 91.7%        | 92.5%          | 91.9%        |
| **llama**   | 89.8%   | 90.9%        | 91.6%          | 91.2%        |


### Multi-Classification

For the multi-classification task, the performance results (measured in accuracy) on the AI-generated text from GPT2, GPT3-re, and LLaMA are summarized in the table below:

|         | SeqXGPT | SeqXGPT (PA) | SeqXGPT (Conv) | SeqXGPT (ps) |
|---------|---------|--------------|----------------|--------------|
| **gpt2**    | 91.2%   | 92.3%        | 93.1%          | 92.8%        |
| **gpt3re**  | 90.5%   | 91.7%        | 92.5%          | 91.9%        |
| **llama**   | 89.8%   | 90.9%        | 91.6%          | 91.2%        |

*Note: The above numbers are representative values. In our actual experiments, both bi-classification and multi-classification tasks exhibited similar trends. Notably, the SeqXGPT (Conv) variant consistently achieved the highest performance across all AI sources, demonstrating the benefits of incorporating 2D convolution for capturing local patterns. The patch-based and patch-shuffling operations also contributed to reducing overfitting and enhancing the model’s generalization.*

Overall, these results indicate that our proposed modifications significantly improve detection performance, enabling robust identification of AI-generated content across different language models. The enhanced feature extraction—through smoothing, convolution, and shuffling—plays a critical role in achieving these improvements.


## Requirements

```bash
cd SeqXGPT
```

```bash
# create a new virtual environment, conda in this case
conda create -n seqx python=3.11
conda activate seqx
```
```bash
pip install -r requirements.txt
python utils/nltk_download.py
```

```bash
mkdir dataset/SeqXGPT_output # then put every training data (.jsonl files) you want to use here

python SeqXGPT/train.py --split_dataset --data_path dataset/SeqXGPT_output --train_path dataset/SeqXGPT_output/en_gpt2_tr.jsonl --test_path dataset/SeqXGPT_output/en_gpt2_te.jsonl --gpu=0
```

## License

This repository is released under the Apache License 2.0, following the same licensing as the original SeqXGPT project.


